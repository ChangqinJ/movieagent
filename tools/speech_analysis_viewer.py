#!/usr/bin/env python3
"""
Speech Analysis Viewer - æŸ¥çœ‹å’Œåˆ†æä¿å­˜çš„è¯­éŸ³åˆ†æç»“æœ

ä½¿ç”¨æ–¹æ³•:
1. æŸ¥çœ‹æŸä¸ªå·¥ä½œç›®å½•çš„è¯­éŸ³åˆ†ææ±‡æ€»:
   python tools/speech_analysis_viewer.py --working-dir .working_dir/6

2. æŸ¥çœ‹ç‰¹å®šshotçš„è¯¦ç»†åˆ†æ:
   python tools/speech_analysis_viewer.py --shot-analysis .working_dir/6/shots/0_video_speech_analysis.json

3. å¯¼å‡ºæ—¶é—´è½´åˆ°CSV:
   python tools/speech_analysis_viewer.py --working-dir .working_dir/6 --export-csv timeline.csv
"""

import os
import json
import argparse
import csv
from typing import Dict, List, Optional
from datetime import datetime


class SpeechAnalysisViewer:
    """æŸ¥çœ‹å’Œå¤„ç†è¯­éŸ³åˆ†æç»“æœçš„å·¥å…·"""
    
    def __init__(self):
        pass
    
    def view_summary(self, working_dir: str) -> Optional[Dict]:
        """æŸ¥çœ‹è¯­éŸ³åˆ†ææ±‡æ€»"""
        shots_dir = os.path.join(working_dir, "shots")
        summary_path = os.path.join(shots_dir, "speech_analysis_summary.json")
        
        if not os.path.exists(summary_path):
            print(f"âŒ æ‰¾ä¸åˆ°è¯­éŸ³åˆ†ææ±‡æ€»æ–‡ä»¶: {summary_path}")
            return None
        
        try:
            with open(summary_path, 'r', encoding='utf-8') as f:
                summary = json.load(f)
            
            print("=" * 60)
            print("ğŸ¬ è¯­éŸ³åˆ†ææ±‡æ€»æŠ¥å‘Š")
            print("=" * 60)
            print(f"ğŸ“… åˆ†ææ—¶é—´: {summary.get('analysis_timestamp', 'Unknown')}")
            print(f"ğŸ¥ æ€»shotæ•°: {summary.get('total_shots', 0)}")
            print(f"ğŸ—£ï¸ æ€»è¯­éŸ³æ®µæ•°: {summary.get('total_speech_segments', 0)}")
            print()
            
            shots_analyzed = summary.get('shots_analyzed', [])
            for i, shot in enumerate(shots_analyzed):
                print(f"Shot {i}:")
                print(f"  ğŸ“ æ–‡ä»¶: {os.path.basename(shot.get('video_path', ''))}")
                print(f"  ğŸ—£ï¸ è¯­éŸ³æ®µæ•°: {shot.get('speech_segments_count', 0)}")
                
                # æ˜¾ç¤ºè¯­éŸ³æ®µè¯¦æƒ…
                speech_segments = shot.get('speech_segments', [])
                for j, segment in enumerate(speech_segments):
                    start_time = segment.get('start_time', 0)
                    end_time = segment.get('end_time', 0)
                    speaker = segment.get('speaker', 'Unknown')
                    confidence = segment.get('confidence', 0)
                    print(f"    æ®µ {j+1}: {speaker} | {start_time:.1f}s - {end_time:.1f}s | ç½®ä¿¡åº¦: {confidence:.2f}")
                
                if shot.get('analysis_notes'):
                    print(f"  ğŸ“ åˆ†ææ³¨é‡Š: {shot['analysis_notes']}")
                print()
            
            return summary
            
        except Exception as e:
            print(f"âŒ è¯»å–æ±‡æ€»æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def view_shot_analysis(self, analysis_file_path: str) -> Optional[Dict]:
        """æŸ¥çœ‹ç‰¹å®šshotçš„è¯¦ç»†åˆ†æ"""
        if not os.path.exists(analysis_file_path):
            print(f"âŒ æ‰¾ä¸åˆ°åˆ†ææ–‡ä»¶: {analysis_file_path}")
            return None
        
        try:
            with open(analysis_file_path, 'r', encoding='utf-8') as f:
                analysis = json.load(f)
            
            print("=" * 60)
            print("ğŸ¥ å•ä¸ªShotè¯­éŸ³åˆ†æè¯¦æƒ…")
            print("=" * 60)
            print(f"ğŸ“ è§†é¢‘æ–‡ä»¶: {analysis.get('video_path', 'Unknown')}")
            print()
            
            # æ˜¾ç¤ºåŸå§‹å“åº”ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if 'raw_response' in analysis:
                print("ğŸ¤– AIæ¨¡å‹åŸå§‹å“åº”:")
                print("-" * 40)
                print(analysis['raw_response'][:500] + "..." if len(analysis['raw_response']) > 500 else analysis['raw_response'])
                print()
            
            # æ˜¾ç¤ºè§£æç»“æœ
            if 'parsed_result' in analysis:
                parsed = analysis['parsed_result']
                print("ğŸ“Š è§£æç»“æœ:")
                print(f"  è¯´è¯äºº: {parsed.get('speaker', 'Unknown')}")
                if 'analysis_notes' in parsed:
                    print(f"  åˆ†ææ³¨é‡Š: {parsed['analysis_notes']}")
                print()
            
            # æ˜¾ç¤ºè¯­éŸ³æ®µ
            speech_segments = analysis.get('speech_segments', [])
            print(f"ğŸ—£ï¸ è¯­éŸ³æ®µè¯¦æƒ… (å…±{len(speech_segments)}æ®µ):")
            for i, segment in enumerate(speech_segments):
                start_time = segment.get('start_time', 0)
                end_time = segment.get('end_time', 0)
                speaker = segment.get('speaker', 'Unknown')
                confidence = segment.get('confidence', 0)
                duration = end_time - start_time
                print(f"  æ®µ {i+1}: {speaker}")
                print(f"    â° æ—¶é—´: {start_time:.1f}s - {end_time:.1f}s (æ—¶é•¿: {duration:.1f}s)")
                print(f"    ğŸ¯ ç½®ä¿¡åº¦: {confidence:.2f}")
                print()
            
            return analysis
            
        except Exception as e:
            print(f"âŒ è¯»å–åˆ†ææ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def export_timeline_csv(self, working_dir: str, output_csv: str):
        """å¯¼å‡ºæ—¶é—´è½´åˆ°CSVæ–‡ä»¶"""
        shots_dir = os.path.join(working_dir, "shots")
        summary_path = os.path.join(shots_dir, "speech_analysis_summary.json")
        
        if not os.path.exists(summary_path):
            print(f"âŒ æ‰¾ä¸åˆ°è¯­éŸ³åˆ†ææ±‡æ€»æ–‡ä»¶: {summary_path}")
            return
        
        try:
            with open(summary_path, 'r', encoding='utf-8') as f:
                summary = json.load(f)
            
            # å‡†å¤‡CSVæ•°æ®
            csv_data = []
            shots_analyzed = summary.get('shots_analyzed', [])
            
            for shot_idx, shot in enumerate(shots_analyzed):
                video_file = os.path.basename(shot.get('video_path', ''))
                speech_segments = shot.get('speech_segments', [])
                
                for segment_idx, segment in enumerate(speech_segments):
                    csv_data.append({
                        'shot_index': shot_idx,
                        'video_file': video_file,
                        'segment_index': segment_idx,
                        'speaker': segment.get('speaker', 'Unknown'),
                        'start_time': segment.get('start_time', 0),
                        'end_time': segment.get('end_time', 0),
                        'duration': segment.get('end_time', 0) - segment.get('start_time', 0),
                        'confidence': segment.get('confidence', 0)
                    })
            
            # å†™å…¥CSV
            if csv_data:
                with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:
                    fieldnames = ['shot_index', 'video_file', 'segment_index', 'speaker', 
                                'start_time', 'end_time', 'duration', 'confidence']
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    
                    writer.writeheader()
                    for row in csv_data:
                        writer.writerow(row)
                
                print(f"âœ… æ—¶é—´è½´æ•°æ®å·²å¯¼å‡ºåˆ°: {output_csv}")
                print(f"ğŸ“Š å…±å¯¼å‡º {len(csv_data)} æ¡è¯­éŸ³æ®µè®°å½•")
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°è¯­éŸ³æ®µæ•°æ®å¯å¯¼å‡º")
                
        except Exception as e:
            print(f"âŒ å¯¼å‡ºCSVå¤±è´¥: {e}")
    
    def list_available_analyses(self, working_dir: str):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„åˆ†ææ–‡ä»¶"""
        shots_dir = os.path.join(working_dir, "shots")
        
        if not os.path.exists(shots_dir):
            print(f"âŒ æ‰¾ä¸åˆ°shotsç›®å½•: {shots_dir}")
            return
        
        # æŸ¥æ‰¾åˆ†ææ–‡ä»¶
        analysis_files = [f for f in os.listdir(shots_dir) if f.endswith('_speech_analysis.json')]
        summary_file = os.path.join(shots_dir, "speech_analysis_summary.json")
        
        print("=" * 60)
        print("ğŸ“‹ å¯ç”¨çš„è¯­éŸ³åˆ†ææ–‡ä»¶")
        print("=" * 60)
        
        if os.path.exists(summary_file):
            print(f"ğŸ“Š æ±‡æ€»æ–‡ä»¶: {summary_file}")
        else:
            print("âŒ æœªæ‰¾åˆ°æ±‡æ€»æ–‡ä»¶")
        
        print(f"\nğŸ¥ Shotåˆ†ææ–‡ä»¶ (å…±{len(analysis_files)}ä¸ª):")
        for analysis_file in sorted(analysis_files):
            full_path = os.path.join(shots_dir, analysis_file)
            print(f"  - {full_path}")


def main():
    parser = argparse.ArgumentParser(description="è¯­éŸ³åˆ†æç»“æœæŸ¥çœ‹å™¨")
    parser.add_argument("--working-dir", "-w", help="å·¥ä½œç›®å½•è·¯å¾„")
    parser.add_argument("--shot-analysis", "-s", help="æŸ¥çœ‹ç‰¹å®šshotçš„åˆ†ææ–‡ä»¶")
    parser.add_argument("--export-csv", "-c", help="å¯¼å‡ºæ—¶é—´è½´åˆ°CSVæ–‡ä»¶")
    parser.add_argument("--list", "-l", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„åˆ†ææ–‡ä»¶")
    
    args = parser.parse_args()
    
    viewer = SpeechAnalysisViewer()
    
    if args.shot_analysis:
        # æŸ¥çœ‹ç‰¹å®šshotåˆ†æ
        viewer.view_shot_analysis(args.shot_analysis)
    
    elif args.working_dir:
        if args.list:
            # åˆ—å‡ºå¯ç”¨æ–‡ä»¶
            viewer.list_available_analyses(args.working_dir)
        elif args.export_csv:
            # å¯¼å‡ºCSV
            viewer.export_timeline_csv(args.working_dir, args.export_csv)
        else:
            # æŸ¥çœ‹æ±‡æ€»
            viewer.view_summary(args.working_dir)
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
